{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Regressão Logística\n",
        "\n",
        "## Revisando\n",
        "\n",
        "A regressão logística é um método de classificação que estima a probabilidade de uma instância pertencer a uma classe específica.\n",
        "\n",
        "Em vez de prever valores contínuos (como na regressão linear), a regressão logística prevê a probabilidade de uma observação pertencer a uma das categorias de uma variável binária dependente. Em outras palavras, a resposta pode assumir valores sim/não, verdadeiro/falso, 0/1.\n",
        "\n",
        "> **Observação:** Os códigos a seguir não são executáveis, pois faltam dados. São apenas exemplos para ilustrar as classes e métodos a serem utilizados nesta aula.\n",
        "\n",
        "A classe `LogisticRegression` do scikit-learn fornece uma implementação conveniente para ajustar um modelo de regressão logística."
      ],
      "metadata": {
        "id": "RQ95aCZ3NtTD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n"
      ],
      "metadata": {
        "id": "OkPsykVdQ1M2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inicialização do Modelo\n",
        "Podemos inicializar um modelo de regressão logística com diversos parâmetros. Aqui estão alguns dos mais importantes:\n",
        "\n",
        "- **penalty**: Especifica a norma usada na penalização (regularização). Pode ser `l1`, `l2`, `elasticnet`, ou `None`.\n",
        "- **C**: Parâmetro de regularização inversa; quanto menor o valor de `C`, maior a regularização.\n",
        "- **solver**: Algoritmo a ser usado na otimização do problema. Pode ser `newton-cg`, `lbfgs`, `liblinear`, `sag`, ou `saga`.\n",
        "- **max_iter**: Número máximo de iterações para os solvers de otimização.\n",
        "- **random_state**: Semente usada pelo gerador de números aleatórios.\n",
        "\n",
        "Exemplo de inicialização:"
      ],
      "metadata": {
        "id": "2lJjobifQ4AT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = LogisticRegression(penalty='l2', C=1.0, solver='lbfgs', max_iter=100, random_state=42)\n"
      ],
      "metadata": {
        "id": "sR_qGvrhQ9Ou"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Treinando o Modelo\n",
        "Após inicializar o modelo, podemos ajustá-lo aos dados de treinamento:\n"
      ],
      "metadata": {
        "id": "V5vvRaHbQ-yo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "id": "77C7Kt1UQ3fV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Fazendo Previsões\n",
        "É possível usar o modelo treinado para fazer previsões tanto das classes quanto das probabilidades:\n"
      ],
      "metadata": {
        "id": "JJob7GrrRJEI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prevendo as classes:\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Prevendo as probabilidades:\n",
        "y_prob = model.predict_proba(X_test)"
      ],
      "metadata": {
        "id": "ZGL2KsPWROpY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Avaliação do Modelo\n",
        "Depois de fazer as previsões, podemos avaliar o desempenho do modelo usando diferentes métricas:"
      ],
      "metadata": {
        "id": "DbJa_DzcRfu-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Acurácia\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Acurácia: {accuracy}')\n",
        "\n",
        "# Matriz de Confusão\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(f'Matriz de Confusão:\\n{cm}')\n",
        "\n",
        "# Relatório de Classificação:\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "report = classification_report(y_test, y_pred)\n",
        "print(f'Relatório de Classificação:\\n{report}')"
      ],
      "metadata": {
        "id": "D8p_nu8JRVgs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Interpretação dos Coeficientes\n",
        "Os coeficientes do modelo indicam a relação entre as variáveis independentes e a variável dependente. Valores positivos indicam que o aumento da variável independente está associado a um aumento na probabilidade do evento, enquanto valores negativos indicam uma associação inversa."
      ],
      "metadata": {
        "id": "8Y5NRNHqQZTi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "coefficients = model.coef_[0]\n",
        "feature_names = X.columns\n",
        "coef_df = pd.DataFrame({'Variável': feature_names, 'Coeficiente': coefficients})\n",
        "\n",
        "print(coef_df)\n"
      ],
      "metadata": {
        "id": "EizzGACSR4Kn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exemplo Completo\n",
        "O exemplo a seguir utiliza dados hipotéticos de um processo seletivo de um programde Doutorado. Nesse processo, são considerados pontos de conhecimento em Computação (representados pela nota do POSCOMP, um exame nacional aplicado pela SBC), a nota obtida em um exame de inglês e a quantidade de artigos publicados pelo candidato. Nosso objetivo é determinar se o candidato será aprovado ($1$) ou não ($0$) nesse processo seletivo.\n",
        "\n",
        "## Preparação dos Dados\n",
        "Antes de construir o modelo, é essencial preparar os dados. Isso inclui a limpeza, transformação e normalização dos dados. No nosso caso, não existem dados nulos ou faltantes (ou seja, `na`). Além disso, não é necessário fazer a transformação dos dados (essa seria útil caso houvesse grande diferença de escalas, ou se algum valor fosse categórico).\n",
        "\n",
        "No nosso caso, basta apenas ler a planilha."
      ],
      "metadata": {
        "id": "m5tnmZBwZQ_X"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UPpUIuuq9Tt0"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Carregar os dados\n",
        "data = pd.read_csv('dados_poscomp.csv')\n",
        "\n",
        "# Informações sobre os dados\n",
        "print(\"Cabeçalho da tabela\")\n",
        "print(data.head())\n",
        "print(\"Dimensões da tabela\")\n",
        "print(data.shape)\n",
        "print(\"Estatísticas da tabela\")\n",
        "print(data.describe())\n",
        "print(\"Informações da tabela\")\n",
        "print(data.info())\n",
        "print(\"Tipos de dados das colunas\")\n",
        "print(data.dtypes)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Limpeza dos dados, se necessário (exemplo: removendo valores nulos)\n",
        "# data = data.dropna()\n",
        "\n",
        "# Transformação de variáveis categóricas, se necessário\n",
        "# data['categoria_codificada'] = data['categoria'].map({'valor1': 0, 'valor2': 1})\n",
        "\n",
        "# Seleção de variáveis independentes e dependentes\n",
        "X = data[['POSCOMP', 'Inglês', 'Artigos publicados']]\n",
        "y = data['Admitido']"
      ],
      "metadata": {
        "id": "AZwVz2sA6GnB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.head()"
      ],
      "metadata": {
        "id": "7IQH_olLZyEu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y.head()"
      ],
      "metadata": {
        "id": "5n6BFIndagMh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Divisão dos Dados em Treinamento e Teste\n",
        "Vamos, agora, dividir os dados em conjuntos de *treinamento* e *teste* para avaliar o desempenho do modelo."
      ],
      "metadata": {
        "id": "vft2Rpwk-cNE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "tAIhi3lW-elQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Construção do Modelo\n",
        "Usaremos, como de costume, a biblioteca `scikit-learn` para construir o modelo de regressão logística."
      ],
      "metadata": {
        "id": "vpMagFYp-eNQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Inicialização do modelo\n",
        "model = LogisticRegression()\n",
        "\n",
        "# Treinamento do modelo\n",
        "model.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "id": "79rR0A_F-ord"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Avaliação do Modelo\n",
        "Para avaliar o desempenho do modelo, vamos considerar as métricas de precisão (*acurácia*) e a matriz de confusão, além de exibir um relatório das classes obtidas. Em seguida, vamos vizualizar a matriz de confusão."
      ],
      "metadata": {
        "id": "lI7bzk7C-uV5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "# Previsões no conjunto de teste\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Avaliação do modelo\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "class_report = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f'Acurácia: {accuracy}')\n",
        "print('Matriz de Confusão:')\n",
        "print(conf_matrix)\n",
        "print('Relatório de Classificação:')\n",
        "print(class_report)"
      ],
      "metadata": {
        "id": "_piId4Yl-wGa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sn\n",
        "\n",
        "confusion_matrix = pd.crosstab(y_test, y_pred, rownames=['Esperado'], colnames=['Predito'])\n",
        "sn.heatmap(confusion_matrix, annot=True)"
      ],
      "metadata": {
        "id": "slb5Ra5CA3nW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Interpretação dos Resultados\n",
        "Finalmente, é importante interpretar os coeficientes do modelo para entender o impacto de cada variável independente."
      ],
      "metadata": {
        "id": "rEf-nEP1-3Aw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Coeficientes do modelo\n",
        "coefficients = model.coef_[0]\n",
        "feature_names = X.columns\n",
        "\n",
        "# Criação de um DataFrame para melhor visualização\n",
        "coef_df = pd.DataFrame({'Variável': feature_names, 'Coeficiente': coefficients})\n",
        "\n",
        "print(coef_df)\n"
      ],
      "metadata": {
        "id": "I1mFmXC3_Joj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Usando o modelo\n",
        "Para finalizar, vamos fazer algumas predições. Vamos considerar um candidato que teve nota $65$ no POSCOMP, $6.0$ no exame de inglês e publicou dois artigos.\n",
        "\n",
        "Como exercício, teste outros cenários (por exemplo, candidato sem publicações, mas com boas notas no POSCOMP)."
      ],
      "metadata": {
        "id": "LNGIFq70BIfF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "teste = {'POSCOMP': 65, 'Inglês': 6, 'Artigos publicados': 2}\n",
        "\n",
        "df = pd.DataFrame(data = teste,index=[0])\n",
        "print(df)"
      ],
      "metadata": {
        "id": "eqQaFVwMBMtp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.predict(df))"
      ],
      "metadata": {
        "id": "UJVdhN93BdH4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.predict_proba(df))"
      ],
      "metadata": {
        "id": "i8XoEMSn8B3Z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}