{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5_g2fU8KKRfq"
      },
      "source": [
        "# Regressão Linear Múltipla: Trabalhando com Planilhas (2)\n",
        "Nesta lição, vamos construir um modelo de regressão linear múltipla, porém utilizando uma outra base de dados - inclusive com dados faltantes! Assim, vamos enfatizar as etapas de pré-processamento dos dados."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_SMLstMiNNVv"
      },
      "source": [
        "## Importando dados\n",
        "Vamos começar, como sempre, importando as bibliotecas e o conjunto de dados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "YfclHwiRKPMZ"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Country</th>\n",
              "      <th>Age</th>\n",
              "      <th>Salary</th>\n",
              "      <th>Purchased</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>France</td>\n",
              "      <td>44.0</td>\n",
              "      <td>72000.0</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Spain</td>\n",
              "      <td>27.0</td>\n",
              "      <td>48000.0</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Germany</td>\n",
              "      <td>30.0</td>\n",
              "      <td>54000.0</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Spain</td>\n",
              "      <td>38.0</td>\n",
              "      <td>61000.0</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Germany</td>\n",
              "      <td>40.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Country   Age   Salary Purchased\n",
              "0   France  44.0  72000.0        No\n",
              "1    Spain  27.0  48000.0       Yes\n",
              "2  Germany  30.0  54000.0        No\n",
              "3    Spain  38.0  61000.0        No\n",
              "4  Germany  40.0      NaN       Yes"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "dataset = pd.read_csv('./Data.csv')\n",
        "dataset.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ARuhlpNMpoo"
      },
      "source": [
        "Neste exemplo, o dataset é formado por um conjunto de informações de compradores de um e-commerce fictício. Cada linha do CSV possui a informação de *Country* (País), *Age* (Idade) e *Salary* (Salário) de um consumidor. A última coluna (*Purchase*) indica se o consumidor comprou ou não na loja virtual. No total, o dataset é formado por 10 consumidores, ou seja, temos 10 observações.\n",
        "\n",
        "Após a importação, precisamos separar o dataset em variável dependente (y) e variável independente (X)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ypiC8xqrM_BW"
      },
      "outputs": [],
      "source": [
        "X = dataset.iloc[:,:-1].values\n",
        "y = dataset.iloc[:,-1].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "NZxMDsIVNBVM"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([['France', 44.0, 72000.0],\n",
              "       ['Spain', 27.0, 48000.0],\n",
              "       ['Germany', 30.0, 54000.0],\n",
              "       ['Spain', 38.0, 61000.0],\n",
              "       ['Germany', 40.0, nan],\n",
              "       ['France', 35.0, 58000.0],\n",
              "       ['Spain', nan, 52000.0],\n",
              "       ['France', 48.0, 79000.0],\n",
              "       ['Germany', 50.0, 83000.0],\n",
              "       ['France', 37.0, 67000.0]], dtype=object)"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "wRSCyzYcNB6V"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['No', 'Yes', 'No', 'No', 'Yes', 'Yes', 'No', 'Yes', 'No', 'Yes'],\n",
              "      dtype=object)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xuIwBz3XNImE"
      },
      "source": [
        "## Lidando com valores ausentes\n",
        "Em aprendizado de máquina, é muito comum que o dataset tenha valores ausentes. Por esse motivo, é essencial adotarmos estratégias para resolução desse problema.\n",
        "\n",
        "Existem duas formas principais de lidar com isso:\n",
        "\n",
        "1. **Remoção:** consiste em remover as linhas com dados ausentes. em geral, essa estratégia é útil quando lidamos com grandes conjuntos de dados e poucos valores ausentes.\n",
        "2. **Substituição:** consiste em substituir o valor ausente por outro valor. Nesse caso, pode-se usar valores como a média ou a mediana das demais observações, ou pelo valor que aparece com mais frequência na base.\n",
        "\n",
        "No nosso exemplo, o `scikit-learn` possui um método, denominado `SimpleImputer`, que permite fazer a substituição. Vamos importar esse método e utilizá-lo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "_jHWoEZGOtY5"
      },
      "outputs": [],
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "imputer = SimpleImputer(missing_values = np.nan, strategy='mean')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JFtogpjJOvxn"
      },
      "source": [
        "Observe que o método possui alguns parâmetros. No caso, `missing_values` indica o \"tipo\" de valor que queremos substituir. Falando de maneira simplificada, estamos procurando um padrão na nossa base e esse padrão será substituído por algo. Nesse exemplo, estamos procurando por valores numéricos ausentes (`np.nan`, ou seja, *not a number*, NaN).\n",
        "\n",
        "O outro argumento que usamos é `strategy`. No caso, indicamos que a substituição será feita pela média (`mean`). Poderíamos usar, alternativamente, a mediana (`median`), o valor mais frequente (`most_frequent`) ou, ainda, uma constante definida por nós mesmos (`constant`). Nesse último caso, teríamos que passar um parâmetro adicional, chamado `fill_value`, com esse valor definido por nós.\n",
        "\n",
        "Uma vez invocado esse comando, devemos aplicá-lo à nossa base (no caso, aos valores de `X`). Para isso, vamos executar os seguintes comandos, indicando que essa busca e substituição deve considerar as três colunas de `X`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "agouj6djQgcN"
      },
      "outputs": [],
      "source": [
        "imputer.fit(X[:,1:3])\n",
        "X[:, 1:3] = imputer.transform(X[:,1:3])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_cUJkCb_Qqdb"
      },
      "source": [
        "Observe, agora, o resultado dessa transformação, que afetou um valor da coluna *Salary* e outro da coluna *Age*:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "bddudsG7QvL5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([['France', 44.0, 72000.0],\n",
              "       ['Spain', 27.0, 48000.0],\n",
              "       ['Germany', 30.0, 54000.0],\n",
              "       ['Spain', 38.0, 61000.0],\n",
              "       ['Germany', 40.0, 63777.77777777778],\n",
              "       ['France', 35.0, 58000.0],\n",
              "       ['Spain', 38.77777777777778, 52000.0],\n",
              "       ['France', 48.0, 79000.0],\n",
              "       ['Germany', 50.0, 83000.0],\n",
              "       ['France', 37.0, 67000.0]], dtype=object)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZaHVMN-Q5zJ"
      },
      "source": [
        "## Lidando com valores categóricos\n",
        "Já vimos como fazer lidar com dados categórios. Vamos, novamente, usar o método `OneHotEncoder` para transformar a coluna `Country` de `X`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "65vn21mjRnW4"
      },
      "outputs": [],
      "source": [
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [0])],remainder = 'passthrough')\n",
        "X = np.array(ct.fit_transform(X))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RqrnvDn0Rmns"
      },
      "source": [
        "Note que passamos como parâmetro a coluna `[0]`, que se refere ao país. Como tínhamos três países. serão inseridas três colunas na base (e a coluna original será removida)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "lIrNdW6wSIxO"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[1.0, 0.0, 0.0, 44.0, 72000.0],\n",
              "       [0.0, 0.0, 1.0, 27.0, 48000.0],\n",
              "       [0.0, 1.0, 0.0, 30.0, 54000.0],\n",
              "       [0.0, 0.0, 1.0, 38.0, 61000.0],\n",
              "       [0.0, 1.0, 0.0, 40.0, 63777.77777777778],\n",
              "       [1.0, 0.0, 0.0, 35.0, 58000.0],\n",
              "       [0.0, 0.0, 1.0, 38.77777777777778, 52000.0],\n",
              "       [1.0, 0.0, 0.0, 48.0, 79000.0],\n",
              "       [0.0, 1.0, 0.0, 50.0, 83000.0],\n",
              "       [1.0, 0.0, 0.0, 37.0, 67000.0]], dtype=object)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3PK2rKASJVM"
      },
      "source": [
        "Também precisamos transformar a variável dependente `y`, cujos valores são `Yes` e `No`. Nesse caso, já temos dados binários, ou seja, podemos simplesmente convertê-los em 0 e 1. Usamos, para isso, o método `LabelEncoder`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "z87aO6gnSqiq"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XUY3U9EhStAW"
      },
      "source": [
        "Note que precisamos, primeiro, instanciar a classe `LabelEncoder` para, então, aplicar o método `fit_transform()`. Como resultado, obtemos:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "GxiGvfowS7oa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0, 1, 0, 0, 1, 1, 0, 1, 0, 1])"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y5T-1J03S8OP"
      },
      "source": [
        "## Separando os dados\n",
        "Já podemos separar nossos dados em *treinamento* e *teste*, como vimos nas últimas lições. Novamente, utilizaremos a função `train_test_split` do `sklearn`, cujo resultado são quatro conjunto de dados: `X_train`, `X_test`, `y_train` e `y_test`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "WWJ1PoIqTnqQ"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "E_baJPXpTtkg"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.0, 1.0, 0.0, 40.0, 63777.77777777778],\n",
              "       [1.0, 0.0, 0.0, 37.0, 67000.0],\n",
              "       [0.0, 0.0, 1.0, 27.0, 48000.0],\n",
              "       [0.0, 0.0, 1.0, 38.77777777777778, 52000.0],\n",
              "       [1.0, 0.0, 0.0, 48.0, 79000.0],\n",
              "       [0.0, 0.0, 1.0, 38.0, 61000.0],\n",
              "       [1.0, 0.0, 0.0, 44.0, 72000.0],\n",
              "       [1.0, 0.0, 0.0, 35.0, 58000.0]], dtype=object)"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "HoGfFlscTtdN"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.0, 1.0, 0.0, 30.0, 54000.0],\n",
              "       [0.0, 1.0, 0.0, 50.0, 83000.0]], dtype=object)"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "UVKB2LfgTss3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1, 1, 1, 0, 1, 0, 0, 1])"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "9VKU8rxrTrUs"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0, 0])"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TlfwTVAxT3Mu"
      },
      "source": [
        "Da maneira como fizemos aqui, já poderíamos aplicar algum método de regressão sobre nossos dados. Observe, porém, que há algo \"estranho\" nessa base: há muita diferença na *grandeza* dos dados. Temos valores binários para representar os países e a saída desejada, valores com duas casas decimais para a idade e valores na casa dos milhares para o salário. Isso pode prejudicar a nossa previsão (**Exercício!**).\n",
        "\n",
        "Vamos, então, aplicar mais uma etapa de pré-processamento sobre o nosso dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wYp7cEO-UxzH"
      },
      "source": [
        "## Escalonando os dados\n",
        "Essa etapa (mais conhecida como *Feature Scaling*) consiste em ajustar as variáveis do dataset de forma a colocá-las em uma mesma escala.\n",
        "\n",
        "Existem duas técnicas de *feature scaling* bastante conhecidas:\n",
        "\n",
        "1. **Padronização:** tem o objetivo de colocar os dados em uma mesma escala, sendo que essa escala tem média 0 e desvio-padrão igual a 1;\n",
        "2. **Normalização:** tem o objetivo de colocar os dados em uma mesma escala; no entanto os valores variam no intervalo de 0 a 1 (ou de -1 a 1, no caso de haver valores negativos nos dados). Essa técnica é mais apropriada para lidar com variáveis que já possuem o comportamento de uma distribuição normal.\n",
        "\n",
        "No nosso exemplo, usamos a técnica de Padronização para as colunas *Age* e *Salary*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "XqbO1VjAWNzT"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "sc = StandardScaler()\n",
        "\n",
        "X_train[:, 3:] = sc.fit_transform(X_train[:,3:])\n",
        "X_test[:, 3:] = sc.transform(X_test[:,3:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "dhcLxs1qWPqY"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0.0 1.0 0.0 0.2630675731713538 0.1238147854838185]\n",
            " [1.0 0.0 0.0 -0.25350147960148617 0.4617563176278856]\n",
            " [0.0 0.0 1.0 -1.9753983221776195 -1.5309334063940294]\n",
            " [0.0 0.0 1.0 0.05261351463427101 -1.1114197802841526]\n",
            " [1.0 0.0 0.0 1.6405850472322605 1.7202971959575162]\n",
            " [0.0 0.0 1.0 -0.08131179534387283 -0.16751412153692966]\n",
            " [1.0 0.0 0.0 0.9518263102018072 0.9861483502652316]\n",
            " [1.0 0.0 0.0 -0.5978808481167128 -0.48214934111933727]]\n"
          ]
        }
      ],
      "source": [
        "print(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "GNgZqevx4aHe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0.0 1.0 0.0 -1.4588292694047795 -0.9016629672292141]\n",
            " [0.0 1.0 0.0 1.984964415747487 2.139810822067393]]\n"
          ]
        }
      ],
      "source": [
        "print(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kh4hqAJxWcwJ"
      },
      "source": [
        "## Exercícios\n",
        "\n",
        "Com os dados já padronizados, agora\n",
        "e a sua vez! Complete esse programa, fazendo as próximas etapas, ou seja: treine o modelo com os dados de treinamento e verifique a sua precisão com os dados de teste. Além disso, refaça esse exemplo *desconsiderando* a etapa de escalonamento dos dados e analise os resultados.\n",
        "\n",
        "Em seguida, encontre outra base de dados (pode ser uma base do próprio `sklearn` ou alguma outra de seu interesse) e aplique as técnicas que você aprendeu até o momento. Repita todos os procedimentos de pré-processamente que forem necessários.\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
