{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Regressão Logistica (1)\n",
        "O primeiro exemplo que veremos de regressão logística está relacionado a um caso de classificação binária univariada. Este é o tipo mais direto de problema de classificação e segue os quatro passos básicos dos problemas de regressão:\n",
        "1. Importar pacotes, funções e classes.\n",
        "2. Obter dados e, se necessário, transformá-los.\n",
        "3. Criar um modelo de classificação e treiná-lo (ou ajustá-lo) com os dados existentes.\n",
        "4. Avaliar o modelo para ver se seu desempenho é satisfatório.\n",
        "\n",
        "Um modelo bem ajustados pode ser usado para fazer previsões adicionais relacionadas a dados novos ou dados não vistos."
      ],
      "metadata": {
        "id": "047kZ-JcdnXg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Função sigmoide\n",
        "Antes de começarmos, propriamente, a discutir os conceitos de regressão logísitca, vamos analisar o comportamento da função sigmoide. Essa função mapeia valores para o intervalo $(0, 1)$ e é definida como:\n",
        "$$f(x)=\\frac{1}{1+\\exp(−x)}$$​\n",
        "\n",
        "Aqui está uma implementação em Python usando a biblioteca NumPy:"
      ],
      "metadata": {
        "id": "Qn5GNQH-BisL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))"
      ],
      "metadata": {
        "id": "GMswGSoyChDL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exemplo de uso (teste com diferentes valores!):"
      ],
      "metadata": {
        "id": "Hl8MQhoJCnSI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "valor = 0.5\n",
        "resultado = sigmoid(valor)\n",
        "print(f\"Resultado da função sigmoide para {valor}: {resultado:.6f}\")"
      ],
      "metadata": {
        "id": "0sl_N23ICqfQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos, também, fazer um gráfico para ilustrar o comportamento dessa função! Para isso, vamos criar um array de valores de $x$ e aplicar a função `sigmoid` sobre esses valores:"
      ],
      "metadata": {
        "id": "7HudsT_mC1G4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Criar um array de valores x\n",
        "x = np.linspace(-5, 5, 100)\n",
        "\n",
        "# Calcular a função sigmoide para os valores de x\n",
        "y = sigmoid(x)"
      ],
      "metadata": {
        "id": "16pnfC1gDA3M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plotar o gráfico\n",
        "plt.plot(x, y)\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('f(x)')\n",
        "plt.title('Função sigmoide')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "QHuOOBDsDbXK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Agora, podemos seguir com nosso estudo de regressão logística!"
      ],
      "metadata": {
        "id": "d65rYkKJDsLI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importando pacotes, funções e classes\n",
        "Primeiramente, precisamos importar o `Matplotlib` para visualização e o `NumPy` para operações de arrays (já fizemos isso, mas vamos repedir aqui, para tornar essa parte independente da anterior).\n",
        "\n",
        "Também precisaremos de `LogisticRegression`, `classification_report()` e `confusion_matrix()` do `scikit-learn`:"
      ],
      "metadata": {
        "id": "RWmSjVxEeiQ4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P_BEgEHibe3A"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Obtendo dados\n",
        "Para este exemplo, vamos apenas criar matrizes para os valores de entrada ($X$) e saída ($y$):"
      ],
      "metadata": {
        "id": "gd7piD0Ce_n8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.arange(10).reshape(-1, 1)\n",
        "y = np.array([0, 0, 0, 0, 1, 1, 1, 1, 1, 1])"
      ],
      "metadata": {
        "id": "dyIVZqe8bmZ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A entrada e a saída devem ser matrizes NumPy (ou seja, instâncias da classe `numpy.ndarray`) ou objetos semelhantes. A função `numpy.arange()` cria uma matriz de valores consecutivos e igualmente espaçados dentro de um determinado intervalo. A matriz `X` deve ser bidimensional, sendo uma coluna para cada entrada, e o número de linhas deve ser igual ao número de observações. Para tornar `X` bidimensional, aplicamos `.reshape()` com os seguintes argumentos:\n",
        "- `-1` para obter quantas linhas forem necessárias\n",
        "- `1` para obter uma coluna\n",
        "\n",
        "Vamos ver, agora, como estão `X` e `y`:"
      ],
      "metadata": {
        "id": "VsGEOetvfQyF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "id": "cSSna44sjoU1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A matriz `X` tem duas dimensões: uma coluna para uma única entrada e dez linhas, cada uma correspondendo a uma observação."
      ],
      "metadata": {
        "id": "ayr2eZaGf29V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "id": "ASkeg72tjpn4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "O vetor `y` é unidimensional com dez itens (novamente, cada item corresponde a uma observação). Ele contém apenas zeros e uns, pois este é um problema de classificação binária."
      ],
      "metadata": {
        "id": "Q1kZYaC9gCKA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Criando e treinando o modelo\n",
        "Depois de preparar a entrada e a saída, podemos criar e definir nosso modelo de classificação. Vamos representá-lo com uma instância da classe `LogisticRegression`:"
      ],
      "metadata": {
        "id": "avVOHVgagMEV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = LogisticRegression(solver='liblinear', random_state=0)"
      ],
      "metadata": {
        "id": "B6-L7ZeUbnoB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A instrução acima cria uma instância de `LogisticRegression` e vincula suas referências ao modelo de variável. Essa classe possui diversos parâmetros opcionais que definem o comportamento do modelo e a abordagem de classificação. A seguir, vamos descrever esse parâmetros:\n",
        "- **penalty** é uma string (`l2` por padrão) que decide se há regularização e qual abordagem usar. Outras opções são `l1`, `elasticnet` e `None`.\n",
        "- **dual** é um booleano (`False` por padrão) que decide se deve usar a formulação primal (quando `False`) ou dual (quando `True`).\n",
        "- **tol** é um número de ponto flutuante (`0.0001` por padrão) que define a tolerância para interromper o procedimento.\n",
        "- **C** é um número de ponto flutuante positivo (`1.0` por padrão) que define a força relativa da regularização. Valores menores indicam regularização mais forte.\n",
        "- **fit_intercept** é um booleano (`True` por padrão) que decide se calcula a interceptação $b_0$ (quando `True`) ou considera esse valor igual a zero (quando `False`).\n",
        "- **intercept_scaling** é um número de ponto flutuante (`1.0` por padrão) que define a escala da interceptação $b_0$.\n",
        "- **class_weight** é um dicionário, `balanced` ou `None` (padrão) que define os pesos relacionados a cada classe. Quando `None`, todas as classes\n",
        "tem o peso um.\n",
        "- *random_state* é um número inteiro, uma instância de `numpy.RandomState` ou `None` (padrão) que define qual gerador de números pseudo-aleatórios usar.\n",
        "- `solver` é uma string (`liblinear` por padrão) que decide qual solucionador usar para ajustar o modelo. Outras opções são `newton-cg`, `lbfgs`, `sag` e `saga`.\n",
        "- **max_iter** é um número inteiro (`100` por padrão) que define o número máximo de iterações pelo solucionador durante o ajuste do modelo.\n",
        "- **multi_class** é uma string (`ovr` por padrão) que decide a abordagem a ser usada para lidar com múltiplas classes. Outras opções são\n",
        "`multinomial` e `auto`.\n",
        "- **verbose** é um número inteiro não negativo (`0` por padrão) que define a verbosidade para os solucionadores `liblinear` e `lbfgs`.\n",
        "- **warm_start** é um booleano (`False` por padrão) que decide se deve reutilizar a solução obtida anteriormente.\n",
        "- **n_jobs** é um número inteiro ou `None` (padrão) que define o número de processos paralelos a serem usados. `None` geralmente significa usar um núcleo, enquanto `-1` significa usar todos os núcleos disponíveis.\n",
        "- **l1_ratio** é um número de ponto flutuante entre zero e um (ou `None`, por padrão). Define a importância relativa da parte *L1* na regularização da rede elástica.\n",
        "\n",
        "Com os parâmetros definidos aqui, a criação do modelo ficou da seguinte maneira:\n",
        "\n",
        "```\n",
        "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True, intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
        "    multi_class='warn', n_jobs=None, penalty='l2', random_state=0, solver='liblinear', tol=0.0001, verbose=0, warm_start=False)\n",
        "```\n",
        "\n",
        "Devemos combinar cuidadosamente o solucionador e o método de regularização por vários motivos. Por exemplo, o solucionador `liblinear` não funciona sem regularização. Os damis (`newton-cg`, `sag`, `saga` e `lbfgs`) não suportam regularização *L1*. Finalmente, `saga` é o único solucionador que suporta regularização de rede elástica.\n"
      ],
      "metadata": {
        "id": "8mmaI7rjgX3A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Depois que o modelo for criado, precisaremos ajustá-lo (ou treiná-lo). O ajuste do modelo é o processo de determinação dos coeficientes $b_0,b_1,\\ldots,b_r$ que correspondem ao melhor valor da função de custo. Nós ajustamos o modelo com o método `.fit()`:"
      ],
      "metadata": {
        "id": "afnNGQZliXwB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X, y)"
      ],
      "metadata": {
        "id": "fhyEbmjybqGE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "É importante observar que podemos usar o fato de que .fit() retorna a instância do modelo e encadeia as duas últimas instruções, como feito na seguinte linha:\n",
        "```\n",
        "model = LogisticRegression(solver='liblinear', random_state=0).fit(X, y)\n",
        "```"
      ],
      "metadata": {
        "id": "CvVlfridjX_S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Neste ponto, temos o modelo de classificação definido.\n",
        "\n",
        "Podemos, assim, obter rapidamente os atributos de nosso modelo. Por exemplo, o atributo `.classes_` representa a matriz de valores distintos que `y` assume:"
      ],
      "metadata": {
        "id": "prN0k3YHxz0y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.classes_"
      ],
      "metadata": {
        "id": "VZy4TZAebsIS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este é o exemplo de classificação binária; portanto `y` pode ser `0` ou `1`, conforme indicado acima.\n",
        "\n",
        "Também podemos obter o valor da inclinação $b_1$ e da interceptação $b_0$ da função linear $f$, assim:"
      ],
      "metadata": {
        "id": "Il4Qe8dEx-pw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.intercept_"
      ],
      "metadata": {
        "id": "WKXlxzTFbxxw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.coef_"
      ],
      "metadata": {
        "id": "MqQzkHkybzAX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Devemos observar que $b_0$ é dado dentro de uma matriz unidimensional, enquanto $b_1$ está dentro de uma matriz bidimensional. Usamos os atributos `.intercept_` e `.coef_` para obter esses resultados."
      ],
      "metadata": {
        "id": "doJlEhrMyYrq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Avaliando o modelo\n",
        "Depois que um modelo foi definido, podemos verificar seu desempenho com o método `.predict_proba()`, que retorna a matriz de probabilidades de que a saída prevista seja igual a `0` ou `1`:"
      ],
      "metadata": {
        "id": "6fokbBjrymE9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict_proba(X)"
      ],
      "metadata": {
        "id": "gOi7NpxPb3kR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Na matriz acima, cada linha corresponde a uma única observação. A primeira coluna é a probabilidade da saída prevista ser zero, ou seja, $1-p(x)$. A segunda coluna é a probabilidade de a saída ser um, ou $p(x)$.\n",
        "\n",
        "Finalmente, podemos obter as previsões reais, com base na matriz de probabilidade e nos valores de $p(x)$ usando o método `.predict()`:"
      ],
      "metadata": {
        "id": "4BDpXsuAy-rc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict(X)"
      ],
      "metadata": {
        "id": "hzpopQFcb5kt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Esta função retorna os valores de saída previstos como uma matriz unidimensional. Comparando com a matriz `X` original, vemos um erro de prvisão no quarto elemento (o valor original dele era `0`). Ou seja, de 10 observações, 9 foram corretamente preditas.\n",
        "\n",
        "Isso signfica que a precisão do nosso modelo é igual a $9/10=0.9$, que podemos verificar com `.score()`:"
      ],
      "metadata": {
        "id": "1abXOR9lzdQ9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.score(X,y)"
      ],
      "metadata": {
        "id": "nfwCmbrsb8pC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "O método `.score()` pega a entrada e a saída como argumentos e retorna a proporção entre o número de previsões corretas e o número de observações.\n",
        "\n",
        "Pode, no entanto, obter mais informações sobre a precisão do modelo com uma matriz de confusão. No caso da classificação binária, a matriz de confusão mostra os seguintes números:\n",
        "- **Verdadeiros negativos** na posição superior esquerda\n",
        "- **Falsos negativos** na posição inferior esquerda\n",
        "- **Falsos positivos** na posição superior direita\n",
        "- **Verdadeiros positivos** na posição inferior direita\n",
        "\n",
        "Para criar a matriz de confusão, usamos a função `confusion_matrix()`, fornecendo as saídas reais e previstas como argumentos:"
      ],
      "metadata": {
        "id": "1QImUWzA0jAB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "confusion_matrix(y, model.predict(X))"
      ],
      "metadata": {
        "id": "yzHGSgUnb_S0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A matriz obtida mostra o seguinte:\n",
        "- Três previsões negativas verdadeiras: As três primeiras observações são zeros previstas corretamente.\n",
        "- Sem previsões falsas negativas: estas são as previstas erroneamente como zeros.\n",
        "- Uma previsão de falso positivo: A quarta observação é um zero que foi erroneamente previsto como um.\n",
        "- Seis previsões positivas verdadeiras: As últimas seis observações são previstas corretamente.\n",
        "\n",
        "Muitas vezes é útil visualizar a matriz de confusão. Podemos fazer isso com `.imshow()` do Matplotlib, que aceita a matriz de confusão como argumento. O código a seguir cria um mapa de calor (*heatmap*) que representa a matriz de confusão:"
      ],
      "metadata": {
        "id": "i6lT-Def1CHJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(y, model.predict(X))\n",
        "fig, ax = plt.subplots(figsize=(8, 8))\n",
        "ax.imshow(cm)\n",
        "ax.grid(False)\n",
        "ax.xaxis.set(ticks=(0, 1), ticklabels=('Predicted 0s', 'Predicted 1s'))\n",
        "ax.yaxis.set(ticks=(0, 1), ticklabels=('Actual 0s', 'Actual 1s'))\n",
        "ax.set_ylim(1.5, -0.5)\n",
        "for i in range(2):\n",
        "  for j in range(2):\n",
        "    ax.text(j, i, cm[i, j], ha='center', va='center', color='red')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "yUvBQnDocCoE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nesta figura, cores diferentes representam números diferentes e cores semelhantes representam números semelhantes. Mapas de calor são uma maneira mais agradável e conveniente de representar uma matriz.\n",
        "\n",
        "Também podemos obter um relatório mais abrangente sobre a classificação com a função `classification_report()`:"
      ],
      "metadata": {
        "id": "1C9EtgxN1eyH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y, model.predict(X)))"
      ],
      "metadata": {
        "id": "jMmsoJwecMqT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Esta função também aceita as saídas reais e previstas como argumentos. Além disso, retorna um relatório sobre a classificação como um dicionário se fornecermos `output_dict=True` como argumento (caso contrário, fornece uma única string).\n",
        "\n",
        "É importante observar que é melhor avaliar o modelo com os dados que **não foram** usados para treinamento. Assim, evitamos vieses e podemos detectar *overfitting*. Nesse exemplo, mas simples, fizemos a análise com todo conjunto de dados."
      ],
      "metadata": {
        "id": "w9WTVOSE6Ngh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Melhorando o modelo\n",
        "Podemos experimentar outros parâmetros para melhorar o modelo. Por exemplo, vamos trabalhar com a força de regularização `C=10.0`, em vez do valor padrão de `C=1.0`:"
      ],
      "metadata": {
        "id": "5pYMlqZc7DNd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = LogisticRegression(solver='liblinear', C=10.0, random_state=0)\n",
        "model.fit(X, y)"
      ],
      "metadata": {
        "id": "fS8waRxGcPJ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Agora temos outro modelo com parâmetros diferentes. Consequentemente, obteremos uma matriz de probabilidade diferente e um conjunto diferente de coeficientes e previsões:"
      ],
      "metadata": {
        "id": "zChyiFlO8YYz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.intercept_"
      ],
      "metadata": {
        "id": "OGMhibvA8pei"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.coef_"
      ],
      "metadata": {
        "id": "gSrwPjqZ9-6-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict_proba(x)"
      ],
      "metadata": {
        "id": "89Dr0hdR-A5y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict(X)"
      ],
      "metadata": {
        "id": "DLSaqAzx-Czq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observe que os valores absolutos da interceptação $b_0$ e do coeficiente $b_1$ são maiores. Isso acontece porque o valor maior de `C` significa regularização mais fraca ou penalização mais fraca relacionada a valores altos de $b_0$ e $b_1$.\n",
        "\n",
        "Valores diferentes de $b_0$ e $b_1$ implicam uma mudança no logit $f(x)$, valores diferentes das probabilidades $p(x)$, uma forma diferente da linha de regressão e, possivelmente, mudanças em outros resultados previstos e desempenho de classificação. O valor limite de $x$ para o qual $p(x)=0.5$ e $f(x)=0$ é maior agora (está acima de $3$). Nesse caso, todas as previsões foram verdadeiras, conforme mostrado pela precisão, matriz de confusão e relatório de classificação:"
      ],
      "metadata": {
        "id": "5U3imqY88w7X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.score(X, y)"
      ],
      "metadata": {
        "id": "VOZjP-3ecRl3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "confusion_matrix(y, model.predict(X))"
      ],
      "metadata": {
        "id": "ovnmxJB9cTws"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y, model.predict(X)))"
      ],
      "metadata": {
        "id": "-9LiV_4scXY9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A pontuação (ou precisão) de 1 e os zeros nos campos inferior esquerdo e superior direito da matriz de confusão indicam que os resultados reais e previstos são os mesmos. Faça o mapa de calor desses resultados, para visualizar melhor!"
      ],
      "metadata": {
        "id": "w9V1wYWW9mr9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercício\n",
        "Refaça os exemplos vistos nesta aula utilizando os seguintes dados:\n",
        "```\n",
        "X = np.arange(10).reshape(-1, 1)\n",
        "y = np.array([0, 1, 0, 0, 1, 1, 1, 1, 1, 1])\n",
        "```\n",
        "Note que, agora, nosso vetor $y$ não é *linearmente separável*, ou seja, seus valores não estão divididos em dois \"blocos\" facilmente separáveis."
      ],
      "metadata": {
        "id": "ElsnruRMEvpQ"
      }
    }
  ]
}